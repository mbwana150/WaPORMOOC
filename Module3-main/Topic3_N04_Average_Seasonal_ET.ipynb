{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Geospatial analyses using WaPOR data**\n",
        "#Topic 3 - Notebook 4: Average Seasonal Evapotranspiration for area of interest\n",
        "In this notebook we will use the WaPOR AETI data downloaded through the Topic3_N01 notebook and shapefile of wheat field in Gezira irrigation scheme and calculate the seasonal AETI per plot and decadal timeseries of AETI for each plot.   \n",
        "The steps are:\n",
        "1. Install and load necessary packages to manage raster files\n",
        "2. Load the .zip file from Topc3_N01 to this session (or create a new .zip)\n",
        "3. Unzip files\n",
        "4. Get the list of files from uploaded zipped file\n",
        "5. Perform the temporal aggregation (sum) of the decadal AETI\n",
        "6. Zonal statistics (compute average AETI per plot for one filed)\n",
        "7. Saving the dataframes computed above to csv files and downlaod them to local folder\n",
        "8. Exercises\n",
        "9. Bonus - Compute time series of decadal AETI per plot.\n",
        "\n"
      ],
      "metadata": {
        "id": "PCw42k2hRewU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RGYMiFmRFcR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1**"
      ],
      "metadata": {
        "id": "2bDeRCCoW7Ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "%%capture\n",
        "!pip install --upgrade xarray  --quiet\n",
        "!pip install --upgrade geopandas --quiet\n",
        "!pip install --upgrade rioxarray --quiet"
      ],
      "metadata": {
        "id": "uDpCDTAgRfmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required packages\n",
        "from osgeo import gdal\n",
        "import xarray as xr\n",
        "import rioxarray as rio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "Sy_poELISE0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **N.B.**\n",
        ">In this notebook we used additional python packages called <font color='steelblue'>**`Xarray`**</font> and <font color='steelblue'>**`rioxarray`**</font>. <font color='steelblue'>**`Xarray`**</font> is a python library which simplifies working with labelled multi-dimension arrays such as stack of rasters and<font color='steelblue'>**`rioxarray`**</font> is an Xarray extension that allows reading and writing a wide variety of geospatial image formats compatible with Geographic Information Systems (GIS). Introducing these packages is out of the scope of this notebook, but **[here](https://tutorial.xarray.dev/overview/xarray-in-45-min.html)** and **[here](https://corteva.github.io/rioxarray/html/getting_started/getting_started.html)** you can find good introductions about the packages which provid you the basic understanding."
      ],
      "metadata": {
        "id": "oiJRtv8E5slJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Pz6ttPIwFe20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qjn7oLuQFhAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2 - Upload .zip to your colab files**\n",
        "We will now upload the .zip file.\n",
        "Execute the command below, click the `Choose Files` button, navigate to where you have saved the .zip file in your local drive and select the zipped file."
      ],
      "metadata": {
        "id": "b3A1fwh1XYlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To upload file.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "IIiJJMq5SJKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Du-YgXglFieD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3 - Unzip files**\n",
        "Unzip the file you have uploaded.\n",
        "The command is:\n",
        " !unzip 'file_path.zip' -d 'folder_to_unzip_path'\n",
        "Replace the file name in the cell below with the name of your own file. You can find the path to your file by clicking on the 3 dots next to the file name in your file explorer to the left and selecting *Copy path*. (If you do not see your files to the left, click on the folder icon to expand the Files panel)"
      ],
      "metadata": {
        "id": "9qjSqRmfGu9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the uploaded zipfile\n",
        "!unzip '/content/WaPOR_data.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "i4jl-KQYGzKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Step 4 - Get the list of files from uploaded zipped file**\n",
        "The list of files can be obtained in the following way.\n",
        "```python\n",
        "# Example to get all the files with '.tif' extension\n",
        "glob.glob('/content/WaPOR_data/L3-AETI-D/*.tif')\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "jN_8iv-OXg1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rst_fh = glob.glob('/content/WaPOR_data/L3-AETI-D/*.tif')\n",
        "rst_fh # this holds the list of raster files found in the 'L3-AETI-D.zip' file."
      ],
      "metadata": {
        "id": "f5UdO86Yqgw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xPJSCrhzFkTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 5: Perform the temporal aggregation (sum) of the decadal AETI**"
      ],
      "metadata": {
        "id": "sXc-CVCGZOC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create an xarray dataarray from the raster files so that any further computation is easier to do"
      ],
      "metadata": {
        "id": "LFWSpbJlZtLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an xarray dataarray from the raster files so that any further computation is easier to do\n",
        "\n",
        "# get the time of the rasters from filenames\n",
        "time = [pd.to_datetime(i[-14:-4], format='%Y-%m-%d') for i in rst_fh]\n",
        "\n",
        "# read the first raster to get the crs and scale_factor\n",
        "tif_0 = rio.open_rasterio(rst_fh[0])\n",
        "crs = tif_0.rio.crs\n",
        "scale_factor = tif_0.attrs['scale_factor']\n",
        "\n",
        "# read each raster and concatenate them to create an xarray dataarray\n",
        "ds = xr.concat([rio.open_rasterio(f) for f in rst_fh], dim=time)\n",
        "ds = ds.squeeze(dim = 'band', drop = True)\n",
        "ds = ds.drop_vars(['spatial_ref'])\n",
        "\n",
        "# rename the dimnesions of the dataarray\n",
        "ds = ds.rename({'concat_dim':'time','x': 'longitude','y': 'latitude'})\n",
        "\n",
        "# multiply the data by the scale factor\n",
        "ds = ds.where(ds !=ds.attrs['_FillValue'])*scale_factor\n",
        "\n",
        "# write CRS information to the dataarray\n",
        "ds = ds.rio.write_crs(crs, inplace=True)\n",
        "\n",
        "# update the attributes of the dataarray\n",
        "attrs = ds.attrs\n",
        "attrs.update({'start_date': '2022-10-01',\n",
        "              'end_date': '2023-04-30',\n",
        "              '_FillValue': np.nan})\n",
        "attrs_to_delet = [i for i in attrs if 'STATISTICS_' in i]\n",
        "attrs_to_delet.append('number_of_days')\n",
        "attrs_new = {key: attrs[key] for key in attrs if key not in attrs_to_delet}\n",
        "\n",
        "ds.attrs  = attrs_new"
      ],
      "metadata": {
        "id": "HctA3gefsKvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute the seasonal sum of AETI"
      ],
      "metadata": {
        "id": "rfF_yaN4Z6cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can sum up all the decadal taster to seasonal raster.\n",
        "seasonal_year='YE-{0}'.format('Nov')  # the season we use is from November 2022 to April 2023\n",
        "# sum the decadal AETI to seasonal AETI\n",
        "ds_season = ds.sum(dim='time',skipna=False)\n",
        "ds_season = ds_season.drop_vars(['spatial_ref'])\n",
        "ds_season = ds_season.rename('Seasonal AETI')\n",
        "ds_season = ds_season.rio.write_crs(crs)\n",
        "ds_season"
      ],
      "metadata": {
        "id": "WPzkFDUhwj4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update attributes of the seasonal dataarray\n",
        "\n"
      ],
      "metadata": {
        "id": "mBuyU7kIzgtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attrs = ds_season.attrs\n",
        "attrs.update({'start_date': '2022-10-01',\n",
        "              'end_date': '2023-04-30',\n",
        "              'units' : 'mm/sdeceason',\n",
        "              'temporal_resolution' : 'Seasonal'})\n",
        "attrs_to_delet = [i for i in attrs if 'STATISTICS_' in i]\n",
        "attrs_to_delet.append('number_of_days')\n",
        "attrs_new = {key: attrs[key] for key in attrs if key not in attrs_to_delet}\n",
        "\n",
        "ds_season.attrs  = attrs_new"
      ],
      "metadata": {
        "id": "k1Tt6Svxzosw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the season sum AETI\n",
        "ds_season.plot()"
      ],
      "metadata": {
        "id": "qSIF3JwNylgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "t1EMmfVEFm1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6 - Zonal statistics (compute average AETI per plot for one field)**"
      ],
      "metadata": {
        "id": "6AvOUgbR2iBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload and read area of interest defined by geojson file using geopandas"
      ],
      "metadata": {
        "id": "T80UmhfL2oq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To upload file.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "KfdzCeEYJrgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Read polygons of fields in the are of interest for wheat fields\n",
        "import warnings; warnings.filterwarnings('ignore', 'GeoSeries.notna', UserWarning)\n",
        "\n",
        "aoi = r\"/content/Fields.geojson\" ## give the correct path of the geojson file here\n",
        "gdf = gpd.read_file(aoi)\n",
        "gdf"
      ],
      "metadata": {
        "id": "F68EU7oHzXoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the plots\n",
        "gdf.plot()"
      ],
      "metadata": {
        "id": "HmMiZzeb9zkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see from the above geopandas dataframe, there are 8 fields with several plot per filed.\n",
        "\n",
        "You can get the name of the fields using the following code."
      ],
      "metadata": {
        "id": "zqCAOnrV3KAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the name of the fields\n",
        "np.unique(gdf['layer'])"
      ],
      "metadata": {
        "id": "C33Fhbxu1pS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the field **`'FakiMusa6'`** as an example.we can select the rows beloging to this field."
      ],
      "metadata": {
        "id": "FPyD_n3J3kKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Select one of the fields (FakiMusa6)\n",
        "farm_field = gdf[gdf['layer']=='FakiMusa6']\n",
        "farm_field\n"
      ],
      "metadata": {
        "id": "GUMjs9aA0p5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This field has several plots. you gen the number of the plots suing the code in the following cell."
      ],
      "metadata": {
        "id": "a59UJlyT323W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of Polygons in FakiMusa6 field\n",
        "len(farm_field)"
      ],
      "metadata": {
        "id": "8LUYZI5S15Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the plots and use the plots polygons to clip the AETI dataarray\n",
        "\n",
        "# creat empty lists to hold the values for each plot\n",
        "AETI_per_plot = [] # to hold the AETI per plot\n",
        "plot_id = [] # to hold ID of the plots\n",
        "plot_area = [] # to hold the area of plots\n",
        "\n",
        "for index, row in farm_field.iterrows(): # iteration through the farm_field dataframe rows\n",
        "  shdf = farm_field.loc[[index]]\n",
        "\n",
        "  if(not shdf.geometry.item().is_empty): # check if the polygon of the plot is not empty\n",
        "      da = ds_season.rio.clip(shdf.geometry, farm_field.crs, all_touched=True)\n",
        "      # compute AAETI of the polygon\n",
        "      da = da.mean(dim=['latitude','longitude']).data\n",
        "\n",
        "      AETI_per_plot.append(da) # add the AETI per polt to the AETI_per_plot list\n",
        "      plot_id.append(shdf.id.values[0]) # add the ID of a plot to plot_id list\n",
        "      plot_area.append(shdf.area.iloc[0]) # add area of the plot polygon to the plot_area list\n",
        "\n",
        "# # round the numbers in AETI and area for each polygon\n",
        "AETI_per_plot = [ np.around(i,2) for i in AETI_per_plot]\n",
        "plot_area = [np.around(i,2) for i in plot_area]"
      ],
      "metadata": {
        "id": "N5n9r5Wd9kB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dataframe can be ceated using the thre lists we created in the above cell as follows:"
      ],
      "metadata": {
        "id": "Zw5fDB8SlOLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creat a Pandas dataframe from the AETI, area and ID of each polygon\n",
        "data={'Plot_ID':plot_id,'Plot_mean_AETI [mm/season]':AETI_per_plot,\n",
        "        'Plot_area [meter square]':plot_area}\n",
        "df = pd.DataFrame(data)\n",
        "df = df.sort_values('Plot_ID',ascending=True)\n",
        "df"
      ],
      "metadata": {
        "id": "JuuSR4eTIC6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To calculate the min, max and mean of the Plot_mean_AETI and Plot_area columns we use the following Panda functions:\n",
        "```python\n",
        "    df.iloc[:,1:] # Selects the the colusm of the dataframe starting from the secon column\n",
        "    .agg(['min', 'max', 'mean']) # aggregate function to calculate the min, max and mean of the selected dataframe columns\n",
        "    .round() # function to round the values of the colums\n",
        "    .astype(int) # to chnage the data type of the columns to integre\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "5fewIQSyjaPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# applying the above functions to get minimum, maximum and mean of the AETI and the area\n",
        "mm = df.iloc[:,1:].agg(['min', 'max', 'mean']).round().astype(int)\n",
        "mm"
      ],
      "metadata": {
        "id": "KBRzX2XkKbIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nk290-gNKy0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 -  Saving the dataframes computed above to csv files and downlaod them to local folder:"
      ],
      "metadata": {
        "id": "ZATq-rLiK25J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for dataframe df\n",
        "farm_name = farm_field.layer.iloc[0]\n",
        "file_name1 = f'AETI_and_Area_per_plot_for_{farm_name}_field.csv'\n",
        "df.to_csv(file_name1)\n",
        "\n",
        "# for dataframe mm\n",
        "file_name2 = f'Stat_for_{farm_name}_field.csv'\n",
        "mm.to_csv(file_name2)\n",
        "\n",
        "#download the two csv files\n",
        "files.download(file_name1)\n",
        "files.download(file_name2)"
      ],
      "metadata": {
        "id": "2WqyxsRNLQaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HBlqRVvvFN6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-success\">\n",
        "\n",
        "## **8 - EXERCISE**:\n",
        "\n",
        ">Do the zonal statistics for field **`'Eltukl10'`** and get the minimum, maximum and mean of the average AETI and the area of plots.\n",
        "\n",
        ">Write down the values (rounded to the integre values) on a peice paper, you will need them to answer questions in the OCW.\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>Hints</summary>\n",
        "\n",
        ">Select the field **`'Eltukl10'`** from the geodataframe (at the 13th cell) and run the last three cells.\n",
        "\n",
        "</details>\n",
        "    \n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "m69VBTyWKa3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vOBeM1dJFPjr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SuqCwe1pmakL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9 - Bonus - decadal AETI time series**\n",
        "In you want to get a timeseries of decadal AETI per plot, you can run the following three cells and asa exercise try to do the same for field **`'Eltukl10'`**\n",
        "\n",
        "### **Steps:**\n",
        "\n",
        "\n",
        "1. Use the same filed as above (FakiMusa6) and the decadal data\n",
        "2. Iterate over the plot of the field, clip the dataarray by each plot and compute the average AETI per plot\n",
        "3. Save the result of each iteration in a dictionary (decadal_AETI)\n",
        "4. Convert the dictionary to a dataframe\n",
        "5. assign the dataarray time to index of the dataframe\n",
        "6. Plot the dataframe\n",
        "\n"
      ],
      "metadata": {
        "id": "kicqz-aGNx9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decadal_AETI = {}\n",
        "\n",
        "ds = ds.where(ds!=ds.attrs['_FillValue'])\n",
        "\n",
        "for index, row in farm_field.iterrows():\n",
        "  shdf = farm_field.loc[[index]]\n",
        "\n",
        "  if(not shdf.geometry.item().is_empty):\n",
        "      da = ds.rio.clip(shdf.geometry, farm_field.crs, all_touched=True, drop=True)\n",
        "      # compute AAETI of the polygon\n",
        "      d2 = da.mean(dim=['latitude','longitude'], skipna = True)\n",
        "      decadal_AETI[shdf.id.values[0]] = d2.values\n"
      ],
      "metadata": {
        "id": "oPQWi02vK4Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(decadal_AETI)\n",
        "df2.index = ds.time.values\n",
        "df2.round()"
      ],
      "metadata": {
        "id": "Hqvqp-94KAKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the dataframe\n",
        "df2.plot(figsize = (12,6))"
      ],
      "metadata": {
        "id": "dFteYjfSIfG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the dataframe and download to local folder\n",
        "file_name3 = f'decadal_AETI_timeseries_for_{farm_name}_field.csv'\n",
        "df2.to_csv(file_name3)\n",
        "\n",
        "#download the two csv files\n",
        "files.download(file_name3)"
      ],
      "metadata": {
        "id": "IXZGM6z1OxFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # if you want to delete a folder use the code belwo.\n",
        "# !rm -rf /content/L3-AETI-D\n",
        "# !rm -rf /content/tifs\n",
        "# !rm -rf /content/L3-AETI-D.zip"
      ],
      "metadata": {
        "id": "TcaZXDFzHEYX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}